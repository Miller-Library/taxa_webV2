{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# experiments"
      ],
      "id": "261169a4-91b0-45a6-a9b3-7aebbcd1a0fe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install pandas"
      ],
      "id": "2a8e691c-10ff-414a-8f7b-9b5c7320ba5b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Getting to know LLMs and LangChain\n",
        "\n",
        "A foundational element of using LangChain as a wrapper for large\n",
        "language models (LLMs) like GPT4 is the prompt. A prompt in the LLM\n",
        "context is just like a prompt in the usual context: it‚Äôs a thoughtfully\n",
        "designed question meant to elicit a response. If you want to use an LLM\n",
        "to explore text, it is critically important to design an effective\n",
        "prompt that will help the model generate accurate and helpful responses.\n",
        "We are exploring the use of LLMs to help us ‚Äúread‚Äù undergraduate student\n",
        "research papers in marine science and figure out if the paper contains a\n",
        "species occurrence. That is, did the student observe or collect a given\n",
        "species at a given place during the course of their research? If they\n",
        "did, that kind of information is a species occurrence (species + place +\n",
        "date).\n",
        "\n",
        "To explore the potential for using LLMs in this work, we selected a few\n",
        "online tools that are designed to help the user ask questions about text\n",
        "provided to the application. We picked a few student papers at random\n",
        "(all open access) and iterated on a series of questions to learn how to\n",
        "engineer prompts that might give us the information we need to determine\n",
        "if a paper includes a species occurrence. This was our process and what\n",
        "we found.\n",
        "\n",
        "## Tools we tried\n",
        "\n",
        "### Chat My Data üìù ChatPDF üìù Ask My PDF\n",
        "\n",
        "-   [Chat My\n",
        "    Data](https://blog.langchain.dev/tutorial-chatgpt-over-your-data)\n",
        "-   [ChatPDF](https://www.chatpdf.com)\n",
        "-   [Ask My PDF](https://ask-my-pdf.streamlit.app)\n",
        "\n",
        "The first question we gave to each chat tool was, ‚Äú*What is this paper\n",
        "about?*‚Äù\n",
        "\n",
        "# Results"
      ],
      "id": "9510bc09-d179-4cae-ab64-76c72076ed64"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd"
      ],
      "id": "8d8bd507-91f9-479f-8e9e-a64881186f5b"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_861e1_row0_col0, #T_861e1_row0_col1, #T_861e1_row0_col2, #T_861e1_row0_col3, #T_861e1_row1_col0, #T_861e1_row1_col1, #T_861e1_row1_col2, #T_861e1_row1_col3, #T_861e1_row2_col0, #T_861e1_row2_col1, #T_861e1_row2_col2, #T_861e1_row2_col3 {\n",
              "  text-align: left;\n",
              "}\n",
              "</style>\n"
            ]
          }
        }
      ],
      "source": [
        "df = pd.read_csv('data.csv', nrows=3, usecols=[0,1,2,3])\n",
        "df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '100px')])])\n",
        "left_aligned_df = df.style.set_properties(**{'text-align': 'left'})\n",
        "display(left_aligned_df)\n"
      ],
      "id": "cell-tools-test"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing Architectures\n",
        "\n",
        "Having experimented with prompts across some pre-made conversational\n",
        "tools, the next step is to explore different combinations of\n",
        "tools/methods for 1. Load, 2. Transform (Text splitting), 3. Embed, 4.\n",
        "Store, 5. Retrieve (Vector store query). We came up with four main\n",
        "options (below) with some possible variations (see the yellow arrows)."
      ],
      "id": "48edf674-7340-46c0-bad8-0ea44c0a51be"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {}
        }
      ],
      "source": [
        "neato`\n",
        "digraph {\n",
        "    nodesep=0.5;\n",
        "    labelloc = \"b\"\n",
        "    fontname = Arial\n",
        "    node [\n",
        "        shape = rectangle\n",
        "        width = 1.5\n",
        "        color= lightgray\n",
        "        style = filled\n",
        "        fontname=\"Helvetica,Arial,sans-serif\"\n",
        "    ]\n",
        "    edge [\n",
        "    len = 2 \n",
        "    penwidth = 1.5 \n",
        "    arrowhead=open\n",
        "    color= darkgray\n",
        "\n",
        "  ]\n",
        "    start = regular\n",
        "    normalize = 0\n",
        "\n",
        "    subgraph cluster_0 {\n",
        "        style=filled;\n",
        "        color= deepskyblue;\n",
        "        node [style=filled,color=white];\n",
        "        SentenceTransformers -> SentenceTransformerEmbeddings -> Annoy -> MultiQueryRetriever;\n",
        "        label = \"Option #1\";\n",
        "    }\n",
        "\n",
        "    subgraph cluster_1 {\n",
        "        style=filled;\n",
        "        color= yellowgreen;\n",
        "        node [style=filled,color=white];\n",
        "        TikToken -> OpenAIEmbeddings -> FAISS -> ContextualCompression;\n",
        "        label = \"Option #2\";\n",
        "    }\n",
        "\n",
        "subgraph cluster_2 {\n",
        "        style=filled;\n",
        "        color= orange;\n",
        "        node [style=filled,color=white];\n",
        "        NLTK -> LlamaCCP -> Chroma -> ChromaSelfQuerying;\n",
        "        label = \"Option #3\";\n",
        "    }\n",
        "\n",
        "subgraph cluster_3 {\n",
        "        style=filled;\n",
        "        color= deeppink;\n",
        "        node [style=filled,color=white];\n",
        "        SpaCY -> SpaCYEmbeddings -> Chroma2 -> ChromaSelfQuerying2;\n",
        "        label = \"Option #4\";\n",
        "    }\n",
        "\n",
        "subgraph cluster_4 {\n",
        "        margin=40\n",
        "        style=filled;\n",
        "        color= gray;\n",
        "        node [style=filled,color=white];\n",
        "        rankdir=LR;\n",
        "        Stuffing, Refine, MapReduce, MapReRank;\n",
        "    }\n",
        "\n",
        "\n",
        "    source -> PyMuPDF;\n",
        "  PyMuPDF -> SentenceTransformers;\n",
        "  PyMuPDF -> TikToken;\n",
        "  PyMuPDF -> NLTK;\n",
        "  PyMuPDF -> SpaCY;\n",
        "  MultiQueryRetriever -> Stuffing [color = lightblue]\n",
        "  MultiQueryRetriever -> Refine [color = lightblue]\n",
        "  MultiQueryRetriever -> MapReduce [color = lightblue]\n",
        "  MultiQueryRetriever -> MapReRank [color = lightblue]\n",
        "  ContextualCompression -> Stuffing [color = lightblue]\n",
        "  ContextualCompression -> Refine [color = lightblue]\n",
        "  ContextualCompression -> MapReduce [color = lightblue]\n",
        "  ContextualCompression -> MapReRank [color = lightblue]\n",
        "  ChromaSelfQuerying -> Stuffing [color = lightblue]\n",
        "  ChromaSelfQuerying -> Refine [color = lightblue]\n",
        "  ChromaSelfQuerying -> MapReduce [color = lightblue]\n",
        "  ChromaSelfQuerying -> MapReRank [color = lightblue]\n",
        "  ChromaSelfQuerying2 -> Stuffing [color = lightblue]\n",
        "  ChromaSelfQuerying2 -> Refine [color = lightblue]\n",
        "  ChromaSelfQuerying2 -> MapReduce [color = lightblue]\n",
        "  ChromaSelfQuerying2 -> MapReRank [color = lightblue]\n",
        "    FAISS -> MultiQueryRetriever [color = yellow]\n",
        "  Annoy -> ContextualCompression [color = yellow]\n",
        "  LlamaCCP -> FAISS [color = yellow]\n",
        "  OpenAIEmbeddings -> Annoy [color = yellow] \n",
        "\n",
        "    source [shape=Msquare];\n",
        "}\n",
        "`"
      ],
      "id": "c36c88ef-b6fc-493e-a483-01b25133c6fb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {}
        }
      ],
      "source": [
        "neato = require(\"@observablehq/graphviz@0.2\")"
      ],
      "id": "e6942a05-6395-45bb-950c-493e203a7de5"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  }
}